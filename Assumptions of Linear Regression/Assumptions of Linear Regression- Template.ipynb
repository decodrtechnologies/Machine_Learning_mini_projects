{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'area'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import zscore\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and model data\n",
    "## Run the below cells before starting with the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9cafabd84919>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# path = 'forestfires.csv'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m  \u001b[1;31m#Input path for file location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# path = 'forestfires.csv'\n",
    "path = \" \"                                                       #Input path for file location\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_columns = ['area','FFMC','ISI','rain']\n",
    "df = pd.get_dummies(df,columns=['day','month'],drop_first=True)\n",
    "np.log1p(df[out_columns]).skew(), np.log1p(df[out_columns]).kurtosis()\n",
    "mask = df.loc[:,['FFMC']].apply(zscore).abs() < 3\n",
    "df['rain'] = df['rain'].apply(lambda x: int(x > 0.0))\n",
    "df = df[mask.values]\n",
    "out_columns.remove('rain')\n",
    "df[out_columns] = np.log1p(df[out_columns])\n",
    "df[out_columns].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# a categorical variable based on forest fire area damage\n",
    "# No damage, low, moderate, high, very high\n",
    "def area_cat(area):\n",
    "    if area == 0.0:\n",
    "        return \"No damage\"\n",
    "    elif area <= 1:\n",
    "        return \"low\"\n",
    "    elif area <= 25:\n",
    "        return \"moderate\"\n",
    "    elif area <= 100:\n",
    "        return \"high\"\n",
    "    else:\n",
    "        return \"very high\"\n",
    "\n",
    "df['damage_category'] = df['area'].apply(area_cat)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_columns = ['area','FFMC','ISI','rain']\n",
    "df = pd.get_dummies(df,columns=['day','month'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['area','damage_category'])\n",
    "y = df['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Checking assumptions for linear regression in statistics\n",
    "\n",
    "1. Linearity of model\n",
    "    \n",
    "2. Normality of residuals\n",
    "\n",
    "3. Homoscedasticity\n",
    "\n",
    "4. No Autocorrelation\n",
    "\n",
    "5. Multicollinearity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_constant = sm.add_constant(X)\n",
    "\n",
    "# Build OLS model\n",
    "                                                              # Type code here and also get summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linearity of residuals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linearity can be measured by two methods:**\n",
    "\n",
    "- Plot the observed values Vs predicted values` and plot the `Residual Vs predicted values` and see the linearity of residuals. \n",
    "-  Rainbow test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rainbow test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pylab\n",
    "\n",
    "# get an instance of Influence with influence and outlier measures \n",
    "st_resid =                                                                                 #Type Code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Null hypothesis (H0):** The Null hypothesis is that the regression is correctly modeled as linear.\n",
    "- **Alternate hypothesis(H1)**: The model is non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return fstat and p-value\n",
    "                                                                                           # Type code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expectation Mean of residual is zero**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean expected value around 0, it implies linearity is preserved\n",
    "                                                                                   # Calculate mean, type code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def linearity_test(model, y):\n",
    "    '''\n",
    "    Function for visually inspecting the assumption of linearity in a linear regression model.\n",
    "    It plots observed vs. predicted values and residuals vs. predicted values.\n",
    "    \n",
    "    Args:\n",
    "    * model - fitted OLS model from statsmodels\n",
    "    * y - observed values\n",
    "    '''\n",
    "    fitted_vals = model.predict()\n",
    "    resids = model.resid\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "    sns.regplot(x=fitted_vals, y=y, lowess=True, ax=ax[0], line_kws={'color': 'red'})\n",
    "    ax[0].set_title('Observed vs. Predicted Values', fontsize=16)\n",
    "    ax[0].set(xlabel='Predicted', ylabel='Observed')\n",
    "\n",
    "    sns.regplot(x=fitted_vals, y=resids, lowess=True, ax=ax[1], line_kws={'color': 'red'})\n",
    "    ax[1].set_title('Residuals vs. Predicted Values', fontsize=16)\n",
    "    ax[1].set(xlabel='Predicted', ylabel='Residuals')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test linearity using above function \n",
    "linearity_test(lin_reg, y) \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired outcome of plots is that points are symmetrically distributed around a diagonal line in the former plot or around horizontal line in the latter one. \n",
    "\n",
    "> - By observing  the plots the linearity assumption is not there \n",
    "- Adding new features might result in linearity of model \n",
    "- Also, transforming the feature from non-linear to linear using various data transformation techniques can help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normality of the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(lin_reg.resid,fit=stats.norm)\n",
    "plt.text(4,0.5,f\"Skewness: {round(lin_reg.resid.skew(),2)}\",fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test for normality: Jarque Bera**\n",
    "\n",
    "For a good model, the residuals should be normally distributed.\n",
    "The higher the value of Jarque Bera test, the lesser the residuals are normally distributed.\n",
    "\n",
    "The Jarqueâ€“Bera test is a goodness-of-fit test of whether sample data \n",
    "have the skewness and kurtosis matching a normal distribution.\n",
    "\n",
    "The jarque bera test tests whether the sample data has the skewness and kurtosis matching a normal distribution.\n",
    "\n",
    "Note that this test generally works good for large enough number of data samples(>2000) as the test statistics asymptotically has a chi squared distribution with degrees 2 of freedom.\n",
    "\n",
    "**Null hypothesis (H0)** - Residuals are normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Use the Jarque Bera test \n",
    "                                                                                                # Type code here\n",
    "\n",
    "\n",
    "plt.text(-2,4,f\"Jarque bera: {jb}\",fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The p-value is 0 which simply means we can reject out NULL hypothesis.\n",
    "We can fix that by\n",
    "- Removing the outliers in the data\n",
    "- Fixing the Non-linearity in our dependent or target feature\n",
    "- Removing the bias, the bias might be contributing to the non-normality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Homoscedasticity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homoscedacity: If the residuals are symmetrically distributed across the trend , then it is called as homoscedacious. \n",
    "\n",
    "Heteroscedacity: If the residuals are not symmetric across the trend, then it is called as heteroscedacious.\n",
    "\n",
    "\n",
    "**Goldfeld-Quandt test for Homoscedasticity**\n",
    "\n",
    "H0 = constant variance among residuals (Homoscedacity)\n",
    "\n",
    "Ha = Heteroscedacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms.het_goldfeldquandt(lin_reg.resid, lin_reg.model.exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "model =                                                                                        #Type code here\n",
    "fitted_vals =                                                                                  #Type code here\n",
    "resids =                                                                                       #Type code here\n",
    "resids_standardized =                                                                          #Type code here\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "# Use regplot to plot fitted values v/s residuals\n",
    "                                                                                               #Type code here\n",
    "    \n",
    "ax[0].set_title('Predicted vs Residuals', fontsize=16)\n",
    "ax[0].set(xlabel='Predicted Values', ylabel='Residuals')\n",
    "\n",
    "# Use regplot to plot fitted values v/s root of absolute residuals\n",
    "                                                                                               #Type code here\n",
    "    \n",
    "ax[1].set_title('Scale-Location', fontsize=16)\n",
    "ax[1].set(xlabel='Predicted Values', ylabel='sqrt(abs(Residuals))')\n",
    "\n",
    "name = ['F statistic', 'p-value']\n",
    "test = sms.het_goldfeldquandt(model.resid, model.model.exog)\n",
    "lzip(name, test)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- To identify homoscedasticity in the plots, the placement of the points should be equally distributed, random, no pattern (increase/decrease in values of residuals) should be visible and a flat red line.\n",
    "- In the plots we can see there are no paticular patterns and P-Values is also greater than 0.05 ,so we can say that there is homoscedasticity.\n",
    "- Outliers can make it Heteroscedacious, Transforming (log or Box cox, if > 0) the dependent or independent variables can help fix it.\n",
    "\n",
    "[Reference](https://datascienceplus.com/how-to-detect-heteroscedasticity-and-rectify-it/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. No Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation measures the relationship between a variable's current value and its past values.\n",
    "\n",
    "**Test for autocorrelation : Durbin- Watson Test**\n",
    "\n",
    "It's test statistic value ranges from 0-4. If the value is between \n",
    "- 0-2, it's known as Positive Autocorrelation.\n",
    "- 2-4, it is known as Negative autocorrelation.\n",
    "- exactly 2, it means No Autocorrelation.\n",
    "\n",
    "For a good linear model, it should have low or no autocorrelation.\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "durbin_watson(lin_reg.resid)\n",
    "```\n",
    "\n",
    "> In our case, Durbin-Watson: 0.979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as smt\n",
    "# Confidence intervals are drawn as a cone. \n",
    "# By default, this is set to a 95% confidence interval, \n",
    "# suggesting that correlation values outside of this code are very likely a correlation \n",
    "# and not a statistical fluke\n",
    "\n",
    "#Plot autocorrelation \n",
    "acf =                                                                                          #Type code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - By observing the above data we can say that there is positive autocorrelation is present , we can reduce it by using fine tuning our parameters\n",
    "- We can even use Generalize Least Squares (GLS) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multicollinearity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollineariy arises when one independent variable can be linearly predicted by others with a substantial level of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize =(16,10))\n",
    "\n",
    "# Plot heatmap using corelation matrix\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#Calculate variance inflation factor\n",
    "vif =                                                                                         #Type code here\n",
    "pd.DataFrame({'vif': vif[1:]}, index=X.columns).sort_values(by=\"vif\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There is multicollinearity present between some features where vif >5.\n",
    "- We can even use PCA to reduce features to a smaller set of uncorrelated components.\n",
    "- To deal with multicollinearity we should iteratively remove features with high values of VIF.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
